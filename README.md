
# GitHub Users and Repositories Scraper

## Overview
This project involves scraping user data from GitHub based on specific criteria: users located in Hyderabad with more than 50 followers. The project collects relevant user and repository information and stores it in CSV files.

## Key Features
- Scrapes user data from GitHub API.
- Stores user information in `users.csv`.
- Stores public repositories in `repositories.csv`.
- Automatically handles line endings for cross-platform compatibility.

## Explanation of Data Scraping
The data was scraped using the GitHub API by making HTTP requests to fetch users from a specified location and their public repositories. The data is processed to clean and organize it before being saved into CSV files. 

## Interesting Findings
One of the most interesting findings was that many users in Hyderabad have a diverse range of public repositories, showcasing skills in various programming languages and projects. This highlights the vibrant developer community in the city.

## Recommendations for Developers
Developers should consider engaging with the local GitHub community to share knowledge and collaborate on open-source projects. Networking can lead to valuable opportunities and enhanced skills.

## Files Included
- `users.csv`: Contains user data of GitHub users from Hyderabad with more than 50 followers.
- `repositories.csv`: Lists public repositories for the users included in `users.csv`.
- `jj.py`: Python script used to fetch the data from the GitHub API.

## How to Run the Script
To execute the script:
1. Ensure you have Python installed.
2. Install required libraries (if any).
3. Run the script using `python jj.py`.

## License
This project is licensed under the MIT License.
=======
# TDSproj1
>>>>>>> 432026c5a2dfbee83dd5d57f2d070f68f51e6c91
